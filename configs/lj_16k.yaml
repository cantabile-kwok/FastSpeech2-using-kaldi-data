xvector: False
pe: True

model:
    transformer:
        encoder_layer: 4
        encoder_head: 2
        encoder_hidden: 256
        decoder_layer: 6
        decoder_head: 2
        decoder_hidden: 256
        conv_filter_size: 1024
        conv_kernel_size: [ 9, 1 ]
        encoder_dropout: 0.2
        decoder_dropout: 0.2

    variance_predictor:
        filter_size: 256
        kernel_size: 3
        dropout: 0.5

    variance_embedding:
        pitch_quantization: "linear" # support 'linear' or 'log', 'log' is allowed only if the pitch values are not normalized during preprocessing
        energy_quantization: "linear" # support 'linear' or 'log', 'log' is allowed only if the energy values are not normalized during preprocessing
        n_bins: 256

    # gst:
    #   use_gst: False
    #   conv_filters: [32, 32, 64, 64, 128, 128]
    #   gru_hidden: 128
    #   token_size: 128
    #   n_style_token: 10
    #   attn_head: 4

    max_seq_len: 1000

train:
    optimizer:
        batch_size: 16
        betas: [ 0.9, 0.98 ]
        eps: 0.000000001
        weight_decay: 0.0
        grad_clip_thresh: 1.0
        grad_acc_step: 1
        warm_up_step: 4000
        anneal_steps: [ 300000, 400000, 500000 ]
        anneal_rate: 0.3
    step:
        total_step: 900000
        log_step: 100
        synth_step: 1000
        val_step: 1000
        save_step: 100000

data:
    train_utts: "filelists/LJ/train_utts.txt"
    val_utts: "filelists/LJ/val_utts.txt"

    train_utt2phns: "filelists/LJ/text"
    val_utt2phns: "filelists/LJ/text"
    phn2id: "filelists/LJ/phones.txt"

    train_utt2phn_duration: "filelists/LJ/phn_duration"
    val_utt2phn_duration: "filelists/LJ/phn_duration"

    train_feats_scp: "filelists/LJ/train_feats.scp"
    val_feats_scp: "filelists/LJ/val_feats.scp"

    train_utt2spk: "filelists/LJ/train_utt2spk.json"  # this is a json file, not traditional utt2spk
    val_utt2spk: "filelists/LJ/val_utt2spk.json"

    train_var_scp: "filelists/LJ/train_var.scp"
    val_var_scp: "filelists/LJ/val_var.scp"